# Brain Tumor Classification Model  using ResNet-152

This repository contains the code for a brain tumor classification model built using the ResNet-152 architecture in PyTorch. The model is trained to classify different types of brain tumors from MRI images.

## Table of Contents

- [Project Overview](#project-overview)
- [Dataset](#dataset)
- [Installation](#installation)
- [Usage](#usage)
- [Model Architecture](#model-architecture)
- [Training: A Novel Approach](#training-a-novel-approach)
- [Evaluation](#evaluation)
- [Results](#results)

## Project Overview

This project aims to accurately classify various types of brain tumors using a deep learning approach. It leverages transfer learning with a pre-trained ResNet-152 model, which is fine-tuned on a specific dataset of brain tumor MRI images. The goal is to achieve high accuracy in classifying up to 31 different classes of brain abnormalities.

## Dataset

The model is trained on a collection of datasets which were augmented into a one huge chunk  Dataset,to replicate , you can add your own dataset pertinent to your own classification problem  and place in the appropriate directory. The dataset is organized into folders, with each folder representing a different class of brain tumor.

The notebook preprocesses this data by splitting it into training and validation sets with an 80/20 ratio.

## Installation

To run this project, you need to have Python and several libraries installed. You can install the necessary packages using pip:

```bash
pip install torch torchvision matplotlib numpy scikit-learn seaborn
```

## Usage

1. **Clone the repository:**
   ```bash
   git clone https://github.com/your-username/your-repository.git
   ```

2. **Download the dataset:** Make sure to download the NINS Dataset and place it in the designated path as specified in the notebook.

3. **Run the Jupyter Notebook:** Open and run the `Resnet-150-brain-tumor.ipynb` notebook to train and evaluate the model.

## Model Architecture

The model uses a pre-trained ResNet-152 from `torchvision.models`. The final fully connected layer is replaced with a new sequential layer to adapt to the number of classes in the brain tumor dataset. The architecture of the new head is:

- Linear layer (input features from ResNet-152, output 512)
- ReLU activation
- Dropout (p=0.5)
- Linear layer (input 512, output num_classes)

## Training

This project uses a novel training strategy to maximize the performance of the ResNet-152 model on the brain tumor dataset. The core of this approach is the use of a custom-implemented Ranger optimizer, which synergizes multiple advanced optimization techniques.

### The Ranger Optimizer

The RangerOptimizer used in this notebook is a powerful, custom implementation that combines two modern concepts:

- **RAdam (Rectified Adam):** A variant of the Adam optimizer that introduces a term to rectify the variance of the adaptive learning rate. This helps prevent issues during the warm-up phase of training, leading to more stable and reliable convergence.

- **LookAhead:** An optimization technique that works as a wrapper around an inner optimizer (RAdam in this case). It maintains a set of "slow weights" and updates them by looking ahead at the sequence of "fast weights" generated by RAdam. This approach helps in escaping local minima and improves generalization.

### Gradient Centralization (GC)

In addition to the Ranger optimizer, this implementation incorporates Gradient Centralization. GC is a simple and effective technique that operates directly on the gradients by centralizing them to have a zero mean. This technique can:

- Smooth the optimization landscape
- Regularize the weight space, acting as a form of implicit regularization
- Improve the generalization performance of the deep neural network, especially in computer vision tasks

The custom optimizer class allows for applying GC to both convolutional and fully-connected layers, providing an extra layer of optimization for better performance.

### Fine-Tuning Strategy

The overall training process involves:

- **Loss Function:** Standard Cross-Entropy Loss, suitable for this multi-class classification problem
- **Learning Rate:** A low learning rate of 1e-5 is used for fine-tuning the pre-trained ResNet-152 weights
- **Data Augmentation:** The training data is augmented with random horizontal flips and rotations to create a more robust model that is invariant to these transformations

This combination of a powerful pre-trained architecture (ResNet-152) with the advanced Ranger optimizer and Gradient Centralization provides a novel and effective method for this complex medical image classification task.

## Evaluation

The model's performance is evaluated on the validation set using:

- **Accuracy:** Overall and per-class accuracy
- **Precision, Recall, and F1-Score:** Calculated for each class
- **Confusion Matrix:** A normalized confusion matrix is plotted to visualize the classification performance across all classes

## Results

The model achieves high accuracy on the validation set, demonstrating its effectiveness in classifying brain tumors. The final validation accuracy is approximately **98.29%**. Detailed per-class metrics and the confusion matrix can be found in the evaluation section of the notebook.
